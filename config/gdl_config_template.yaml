defaults:
  - model: gdl_unet
  - training: default_training
  - loss: binary/softbce
  - optimizer: adamw
  - callbacks: default_callbacks
  - scheduler: plateau
  - dataset: test_ci_segmentation_binary
  - augmentation: basic_augmentation_segmentation
  - tracker: # set logger here or use command line (e.g. `python GDL.py tracker=mlflow`)
  - visualization: default_visualization
  - inference: default_binary
  - hydra: default
  - override hydra/hydra_logging: colorlog # enable color logging to make it pretty
  - override hydra/job_logging: colorlog # enable color logging to make it pretty
  - _self_

general:
  # path to original working directory
  # hydra hijacks working directory by changing it to the current log directory,
  # so it's useful to have this path as a special variable
  # learn more here: https://hydra.cc/docs/next/tutorials/basic/running_your_app/working_directory
  task: segmentation
  work_dir: ${hydra:runtime.cwd}  # where the code is executed
  config_name: ${hydra:job.config_name}
  config_override_dirname: ${hydra:job.override_dirname}
  config_path: ${hydra:runtime.config_sources}
  project_name: template_project
  workspace: your_name
  max_epochs: 2 # for train only
  min_epochs: 1 # for train only
  raw_data_dir: data
  raw_data_csv: tests/sampling/sampling_segmentation_binary_ci.csv
  sample_data_dir: data # where the hdf5 will be saved
  save_weights_dir: saved_model/${general.project_name}

AWS:
  bucket_name:

print_config: True # save the config in the log folder
mode: {sampling, train, inference, evaluate}
debug: True #False # will print the complete yaml config plus run a validation test
