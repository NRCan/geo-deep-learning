# Deep learning configuration file ------------------------------------------------
# This config is to use massachusetts_buildings image out of the box.
# For that, unzip the file data/massachusetts_buildings.zip befor running images_to_samples.py or other command.
# Five sections :

#   1) Global parameters; those are re-used amongst the next three operations (sampling, training and inference)
#   2) Data analysis parameters
#   3) Sampling parameters
#   4) Training parameters
#   5) Inference parameters
#   6) Visualization parameters

# Global parameters
global:
  samples_size: 512
  num_classes: 1
  data_path: ./data  # path/to/data
  number_of_bands: 3
  # See models/README.md for all the available models.
  model_name: unet
  mlflow_uri: ./mlruns  # path/to/mlflow_tracking_uri
  mlflow_experiment_name: gdl-training  # also used for naming of preprocessing directories
  mlflow_run_name: gdl
  bucket_name:  # name of the S3 bucket where data is stored. Leave blank if using local files
  task: segmentation  # Task to perform. Either segmentation or classification
  num_gpus: 0  # If 0, will run on CPU
  max_used_ram: 2000  # maximum currently used GPU memory (MB) to consider it available (only if num_gpus > 0)
  max_used_perc: 15  # maximum utilization rate (percent) of the GPU to consider it available (only if num_gpus > 0)
  BGR_to_RGB: True
  scale_data: [0,1]
  aux_vector_file:
  aux_vector_attrib:
  aux_vector_ids:
  aux_vector_dist_maps:
  aux_vector_dist_log:
  aux_vector_scale:
  debug_mode: True
  coordconv_convert: False
  coordvonc_scale:


# Data analysis parameters; used in data_analysis.py ------------------
data_analysis:
  create_csv: False
  optimal_parameters_search : False
  sampling_method:  # class_proportion or min_annotated_percent
    'min_annotated_percent': 0  # Min % of non background pixels in samples. Default: 0
    'class_proportion': {'1':0, '2':0, '3':0, '4':0} # See below:
    # keys (numerical values in 'string' format) represent class id
    # values (int) represent class minimum threshold targeted in samples

# Sample parameters; used in images_to_samples.py -------------------
sample:
  prep_csv_file: .data/images_to_samples_ci_csv.csv  # /path/to/csv/images.csv
  val_percent: 20 # Percentage of validation samples created from train set (0 - 100)
  overlap: 5 # (int) Percentage of overlap between 2 chunks.
  sampling_method: # class_proportion or min_annotated_percent
    'min_annotated_percent': 0  # Min % of non background pixels in samples. Default: 0
    'class_proportion': {'1':0, '2':0, '3':0, '4':0} # See below:
    # keys (numerical values in 'string' format) represent class id
    # values (int) represent class minimum threshold targeted in samples
  mask_reference: False


# Training parameters; used in train_segmentation.py ----------------------
training:
  state_dict_path: # optional: path/to/pretrained/file/checkpoint.pth.tar
  num_trn_samples:
  num_val_samples:
  num_tst_samples:
  batch_size: 2
  eval_batch_size: 2
  num_epochs: 1
  target_size: 256
  # See losses/README.md for all Loss function available.
  loss_fn: Lovasz
  # See utils/README.md for all Optimizer available.
  optimizer: adabound
  learning_rate: 0.0001
  weight_decay: 0
  step_size: 4
  gamma: 0.9
  dropout: False   # (bool) Use dropout or not
  dropout_prob:    # (float) Set dropout probability, e.g. 0.5
  class_weights: [1.0, 2.0]
  # Batch metrics (int): The metrics computed every (int) batches.
  # If left blank, will not perform metrics.
  # If (int)=1, metrics computed on all batches.
  batch_metrics:
  # Ignore index (default -> None): the target value that is ignored and
  #                                  does not contribute to the input gradient.
  ignore_index: 255
  # Normalization: parameters for finetuning.
  # for esample
  #    -> mean: [0.485, 0.456, 0.406]
  #    -> std: std: [0.229, 0.224, 0.225])
  normalization:
    mean:
    std:
  # For each augmentation parameters, if not specified,
  # the part of the augmentation will not be performed.
  augmentation:
    # Rotate limit: the upper and lower limits for data rotation.
    rotate_limit: 45
    # Rotate probability: the probability for data rotation.
    rotate_prob: 0.5
    # Horizontal flip: the probability for data horizontal flip.
    hflip_prob: 0.5
    # Range of the random percentile:
    #   the range in which a random percentile value will
    #   be chosen to trim values. This value applies to
    #   both left and right sides of the raster's histogram.
    random_radiom_trim_range: [0.1, 2.0]
    brightness_contrast_range: # Not yet implemented
    noise:  # Standard deviation of Gaussian Noise (optional)


# Inference parameters; used in inference.py --------
inference:
  img_dir_or_csv_file: # /path/to/csv/containing/images/list.csv
  state_dict_path: # optional: /path/to/model/weights/for/inference/checkpoint.pth.tar
  chunk_size: 512 # (int) Size (height and width) of each prediction patch. Default: 512


# Visualization parameters
visualization:
  vis_batch_range: [0,200,10] #start, finish, increment
  vis_at_checkpoint: True
  vis_at_ckpt_min_ep_diff: 0
  vis_at_ckpt_dataset: val # FIXME: Parameter adds confusion. To be removed. Default to val dataset.
  vis_at_init: True
  vis_at_init_dataset: val
  vis_at_evaluation: True #val during training, tst at end of training
  vis_at_train: True
  grid: True
  heatmaps: True
  colormap_file: ./data/colormap.csv
