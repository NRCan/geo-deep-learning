# Deep learning configuration file ------------------------------------------------
# Five sections :
#   1) Global parameters; those are re-used amongst the next three operations (sampling, training and classification)
#   2) Sampling parameters
#   3) Training parameters
#   4) Inference parameters
#   5) Model parameters

# Global parameters

global:
  samples_size: 299
  num_classes: 6
  data_path: ./data
  number_of_bands: 4
  model_name: inception     # One of unet, unetsmall or ternausnet
  bucket_name:   # name of the S3 bucket where data is stored. Leave blank if using local files
  task: classification  # Task to perform. Either segmentation or classification

# Sample parameters; used in images_to_samples.py -------------------

sample:
  prep_csv_file: ./data/images_to_samples_ci_csv.csv
  samples_dist: 200
  remove_background: True
  mask_input_image: False
  mask_reference: False

# Training parameters; used in train_model.py ----------------------

training:
  output_path: ./data
  num_trn_samples: 24
  num_val_samples: 24
  batch_size: 4
  num_epochs: 2
  learning_rate: 0.0001
  weight_decay: 0
  step_size: 4
  gamma: 0.9
  class_weights: False
  batch_metrics: 2

# Inference parameters; used in inference.py --------

inference:
  img_csv_file: ./data/inference_classif_ci_csv.csv
  working_folder: ./data/classification
  state_dict_path: ./data/checkpoint.pth.tar
  chunk_size:
  overlap:

# Models parameters; used in train_model.py and inference.py

models:
  unet:   &unet001
    dropout: False
    probability: 0.2    # Set with dropout
    pretrained: False   # optional
  unetsmall:
    <<: *unet001
  ternausnet:
    pretrained: ./models/TernausNet.pt    # Mandatory
  checkpointed_unet: 
    <<: *unet001
  inception:
    pretrained: False   # optional